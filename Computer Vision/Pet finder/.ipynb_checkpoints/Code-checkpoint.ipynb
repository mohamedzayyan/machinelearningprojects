{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6a72409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import math\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0447866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "\n",
    "train_meta = train_df.copy()\n",
    "test_meta = test_df.copy()\n",
    "train_meta = train_meta.drop([\"Id\", \"Pawpularity\"], axis=1)\n",
    "test_meta = test_meta.drop([\"Id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2acad2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "2  0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
       "3  0018df346ac9c1d8413cfcc888ca8246              0     1     1     1       0   \n",
       "4  001dc955e10590d3ca4673f034feeef2              0     0     0     1       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  \n",
       "0          0      1        0      0          0     0     0           63  \n",
       "1          0      0        0      0          0     0     0           42  \n",
       "2          0      0        0      1          1     0     0           28  \n",
       "3          0      0        0      0          0     0     0           15  \n",
       "4          0      1        0      0          0     0     0           72  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1275c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = train_df.copy()\n",
    "test_image = test_df.copy()\n",
    "\n",
    "train_image[\"file_path\"] = train_df[\"Id\"].apply(lambda x: \"./train/\" + x + \".jpg\")\n",
    "test_image[\"file_path\"] = test_df[\"Id\"].apply(lambda x: \"./test/\" + x + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0411e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_url):\n",
    "    image_string = tf.io.read_file(image_url)\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.central_crop(image, 1.0)\n",
    "    image = tf.image.resize(image, (128, 128))\n",
    "    return image\n",
    "\n",
    "x_train_image=[]\n",
    "for i in train_image['file_path']:\n",
    "    x1=preprocess(i)\n",
    "    x_train_image.append(x1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b04dedc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_image=[]\n",
    "\n",
    "for i in test_image['file_path']:\n",
    "    x1=preprocess(i)\n",
    "    test1_image.append(x1)\n",
    "\n",
    "test1_image=np.array(test1_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3f5ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model() :\n",
    "\n",
    "    # model for Photo image\n",
    "    image_inputs = tf.keras.Input((128, 128 , 3))\n",
    "    x = layers.Conv2D(32, 3, activation=\"relu\")(image_inputs)\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "    block_1_output = layers.MaxPooling2D(3)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_1_output)\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    block_2_output = layers.add([x, block_1_output])\n",
    "\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_2_output)\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    block_3_output = layers.add([x, block_2_output])\n",
    "\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\")(block_3_output)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x_image = layers.Dense(10)(x)\n",
    "\n",
    "    # model for Meta data\n",
    "    meta_inputs = tf.keras.Input(shape=((12,)))\n",
    "    x_meta = tf.keras.layers.Dense(12,activation='relu')(meta_inputs)    \n",
    "    x_meta = tf.keras.layers.Dense(24,activation='relu')(x_meta)    \n",
    "    x_meta = tf.keras.layers.Dense(12,activation='relu')(x_meta)      \n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=1)([x_image, x_meta])\n",
    "    output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[image_inputs, meta_inputs], outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9a1e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b793b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_image = np.array(x_train_image)\n",
    "y_train=train_df['Pawpularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "118a74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess1(image_url, tabular):\n",
    "    image_string = tf.io.read_file(image_url)\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.central_crop(image, 1.0)\n",
    "    image = tf.image.resize(image, (128, 128))\n",
    "    return (image, tabular[1:]), tabular[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c074cc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "67/67 [==============================] - 885s 13s/step - loss: 647.4530 - rmse: 25.5169 - mae: 19.0222 - mape: 78.6691 - val_loss: 0.0000e+00 - val_rmse: 0.0000e+00 - val_mae: 0.0000e+00 - val_mape: 0.0000e+00\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 856s 13s/step - loss: 494.3505 - rmse: 22.2273 - mae: 16.5647 - mape: 78.6743 - val_loss: 441.6988 - val_rmse: 21.0828 - val_mae: 16.4060 - val_mape: 87.4065\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 864s 13s/step - loss: 478.2446 - rmse: 21.8656 - mae: 16.2940 - mape: 79.1828 - val_loss: 426.3113 - val_rmse: 20.7472 - val_mae: 15.6240 - val_mape: 80.3136\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 875s 13s/step - loss: 471.7405 - rmse: 21.7166 - mae: 16.2415 - mape: 79.2307 - val_loss: 424.2014 - val_rmse: 20.7352 - val_mae: 15.1305 - val_mape: 74.5521\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 897s 13s/step - loss: 458.8374 - rmse: 21.4165 - mae: 16.0119 - mape: 78.8262 - val_loss: 424.7005 - val_rmse: 20.7566 - val_mae: 15.0181 - val_mape: 73.0724\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 968s 14s/step - loss: 703.0011 - rmse: 26.6110 - mae: 19.8412 - mape: 79.6983 - val_loss: 0.0000e+00 - val_rmse: 0.0000e+00 - val_mae: 0.0000e+00 - val_mape: 0.0000e+00\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 918s 14s/step - loss: 479.3891 - rmse: 21.8995 - mae: 16.1558 - mape: 80.4182 - val_loss: 502.8209 - val_rmse: 22.6649 - val_mae: 15.7869 - val_mape: 59.1058\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 905s 14s/step - loss: 471.7405 - rmse: 21.7210 - mae: 15.9814 - mape: 80.2388 - val_loss: 439.9444 - val_rmse: 21.1999 - val_mae: 15.2268 - val_mape: 66.5271\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 906s 14s/step - loss: 457.3439 - rmse: 21.3879 - mae: 15.7729 - mape: 79.6376 - val_loss: 431.5528 - val_rmse: 20.9932 - val_mae: 15.2267 - val_mape: 68.3435\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 905s 14s/step - loss: 455.1051 - rmse: 21.3338 - mae: 15.8190 - mape: 80.3017 - val_loss: 436.2695 - val_rmse: 21.1102 - val_mae: 15.1421 - val_mape: 66.4090\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 965s 14s/step - loss: 721.1383 - rmse: 26.9727 - mae: 20.1050 - mape: 76.6219 - val_loss: 0.0000e+00 - val_rmse: 0.0000e+00 - val_mae: 0.0000e+00 - val_mape: 0.0000e+00\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 894s 13s/step - loss: 469.8562 - rmse: 21.6658 - mae: 16.1939 - mape: 76.4766 - val_loss: 439.7457 - val_rmse: 21.0350 - val_mae: 15.0134 - val_mape: 75.1629\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 879s 13s/step - loss: 463.5592 - rmse: 21.5218 - mae: 16.1058 - mape: 76.8276 - val_loss: 432.4646 - val_rmse: 20.8620 - val_mae: 15.0710 - val_mape: 77.3449\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 880s 13s/step - loss: 470.0194 - rmse: 21.6730 - mae: 16.2257 - mape: 76.7099 - val_loss: 432.4275 - val_rmse: 20.8687 - val_mae: 15.0443 - val_mape: 76.9409\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 885s 13s/step - loss: 459.9083 - rmse: 21.4369 - mae: 15.9869 - mape: 76.2852 - val_loss: 430.7613 - val_rmse: 20.8157 - val_mae: 15.0076 - val_mape: 76.9157\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "models = []\n",
    "historys = []\n",
    "tabular_columns = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', \n",
    "                   'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "for train_index, val_index in kf.split(train_meta):      \n",
    "    \n",
    "    x_path = train_image.loc[train_index, \"file_path\"]    \n",
    "    x_val= train_image.loc[val_index, \"file_path\"]\n",
    "    \n",
    "    tabular_train = train_df.loc[train_index, [\"Pawpularity\"] + tabular_columns].values\n",
    "    tabular_val = train_df.loc[val_index, [\"Pawpularity\"] + tabular_columns].values\n",
    "\n",
    "    def step_decay(epoch):\n",
    "        initial_lrate = 0.001\n",
    "        drop = 0.5\n",
    "        epochs_drop = 10.0\n",
    "        lrate = initial_lrate * math.pow(drop, math.floor((epoch)/epochs_drop)\n",
    "        )\n",
    "        return lrate\n",
    "\n",
    "    lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "    earstop = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5)\n",
    "    \n",
    "    model = get_model()\n",
    "    model.compile(\n",
    "        loss = tf.keras.losses.MeanSquaredError(),    \n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\", \"mape\"],\n",
    "        optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "        )\n",
    "    \n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((x_path, tabular_train)).map(preprocess1).shuffle(512).batch(100).cache().prefetch(2)\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices((x_val, tabular_val)).map(preprocess1).batch(100).cache().prefetch(2)\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs = 5,\n",
    "        validation_data = val_ds,\n",
    "        verbose = 1,\n",
    "        callbacks = [lrate, earstop]\n",
    "        )\n",
    "        \n",
    "    historys.append(history)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9af0d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test_data(image_url, tabular):    \n",
    "    image_string = tf.io.read_file(image_url)\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.central_crop(image, 1.0)\n",
    "    image = tf.image.resize(image, (128, 128))    \n",
    "    return (image, tabular), 0\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_image[\"file_path\"], test_df[tabular_columns].values)).map(preprocess_test_data).batch(100).cache().prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99d71868",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for model in models:\n",
    "    nn_pred=model.predict(test_ds)\n",
    "    preds.append(nn_pred)\n",
    "\n",
    "preds_array = np.array(preds)\n",
    "preds_mean = np.mean(preds_array, axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfa655b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>37.763508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>36.853008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e429cead1848a298432a0acad014c9d</td>\n",
       "      <td>37.857426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n",
       "      <td>37.143612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f49844c382931444e68dffbe20228f4</td>\n",
       "      <td>37.400448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b03f7041962238a7c9d6537e22f9b017</td>\n",
       "      <td>38.311924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c978013571258ed6d4637f6e8cc9d6a3</td>\n",
       "      <td>37.318115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>e0de453c1bffc20c22b072b34b54e50f</td>\n",
       "      <td>36.982670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Pawpularity\n",
       "0  4128bae22183829d2b5fea10effdb0c3    37.763508\n",
       "1  43a2262d7738e3d420d453815151079e    36.853008\n",
       "2  4e429cead1848a298432a0acad014c9d    37.857426\n",
       "3  80bc3ccafcc51b66303c2c263aa38486    37.143612\n",
       "4  8f49844c382931444e68dffbe20228f4    37.400448\n",
       "5  b03f7041962238a7c9d6537e22f9b017    38.311924\n",
       "6  c978013571258ed6d4637f6e8cc9d6a3    37.318115\n",
       "7  e0de453c1bffc20c22b072b34b54e50f    36.982670"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub=pd.DataFrame()\n",
    "sub['Id']=test_df['Id']\n",
    "sub['Pawpularity']=preds_mean\n",
    "sub.to_csv('submission.csv',index=False)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b9e30e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
